loop:
  oracle_name: ultrafeedback
  completions_dataset_path: /iopsstor/scratch/cscs/dmelikidze/datasets/combined_annotations_llama
  previous_output_path: null
  previous_checkpoint_path: null
  output_path: null
  logs_path: null
  args_path: null
  outer_loop_batch_size: 64
  rm_training_batch_size: 32
  max_length: 4096
  seed: 4
  replay_buffer_size: 3200
  report_to: wandb
  wandb_project: null

acquisition:
  acquisition_function_type: dts
  acquisition_config: activeuf/acquisition_function/configs.yaml

enn:
  # "meta-llama/Llama-3.2-1B-Instruct", "unsloth/Qwen2.5-1.5B-Instruct", "allenai/OLMo-2-1124-7B-SFT", "allenai/Llama-3.1-Tulu-3-8B-SFT"
  base_model_name_or_path: "unsloth/Qwen2.5-1.5B-Instruct"
  freeze_base_model: false
  feature_extraction_layer: "last_hidden_state"
  num_train_epochs: 1
  save_strategy: "no"
  report_to: "none"
  disable_tqdm: true
  logging_strategy: "steps"
  logging_steps: 1
  lr_scheduler_type: "constant"
  learning_rate: 5e-6
  regularization_towards_initial_weights: 5
  regularization_weight_decay_type: "exponential"
  exponential_decay_base: 0.99
  max_training_steps: 10
  initialization_xavier_gain: 1.0