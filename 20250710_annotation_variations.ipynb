{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba5bb45d",
   "metadata": {},
   "source": [
    "# Annotation experiments\n",
    "\n",
    "We have **60K query prompts**, and for each query prompt, we (will eventually) have **22 responses**. Our goal is to **annotate each completion on four aspects and on its overall quality** using Llama-3.3-70B-Instruct as loaded via vLLM.\n",
    "\n",
    "This notebook tracks our experiments to find the best way to perform these annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695c59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from datasets import load_from_disk\n",
    "import regex as re\n",
    "from tqdm import tqdm\n",
    "\n",
    "models = [\n",
    "    'CohereLabs/c4ai-command-a-03-2025',\n",
    "    'Qwen/Qwen2.5-72B-Instruct',\n",
    "    'Qwen/Qwen3-14B',\n",
    "    'Qwen/Qwen3-30B-A3B',\n",
    "    'Qwen/Qwen3-32B',\n",
    "    'allenai/Llama-3.1-Tulu-3-70B',\n",
    "    'allenai/OLMo-2-0325-32B-Instruct',\n",
    "    'meta-llama/Llama-3.1-8B-Instruct',\n",
    "    'meta-llama/Llama-3.3-70B-Instruct',\n",
    "    'microsoft/phi-4',\n",
    "    'mistralai/Mistral-Small-24B-Instruct-2501',\n",
    "    'nvidia/Llama-3.1-Nemotron-70B-Instruct-HF',\n",
    "    'nvidia/Llama-3_3-Nemotron-Super-49B-v1',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2b5f84",
   "metadata": {},
   "source": [
    "## Variation 0: Annotate responses individually\n",
    "\n",
    "In each message to vLLM, the user's part contains:\n",
    "\n",
    "- Annotation property description\n",
    "- Scoring rubric\n",
    "- Input-output format\n",
    "- One query prompt\n",
    "- **One response**\n",
    "\n",
    "Notes on creating `../datasets/annotations_v0`:\n",
    "\n",
    "- Slow\n",
    "  - ~3h for 60K prompt-response-property triples\n",
    "- Extreme positive bias\n",
    "  - 95% of triples have winning score = 5\n",
    "  - 98% of query prompts have multiple Condorcet winners"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dd1526",
   "metadata": {},
   "source": [
    "## Variation 1: All responses at once\n",
    "\n",
    "In each message to vLLm, the user's part contains:\n",
    "\n",
    "- Annotation property description\n",
    "- Scoring rubric\n",
    "- Input-output format\n",
    "- One query prompt\n",
    "- **All responses**\n",
    "\n",
    "Notes on creating `../datasets/raw_annotations_v1`:\n",
    "\n",
    "- Hallucinations and forgetting\n",
    "- Struggling to follow input-output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088089c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts_v1.py\n",
    "# ====================================\n",
    "#        COMPLETION GENERATION       \n",
    "# ====================================\n",
    "\n",
    "HELPFULNESS_COMPLETION_SYSTEM_PROMPTS = [\n",
    "    \"The assistant should provide users with accurate, relevant, and up-to-date information, ensuring that the content is positive, interesting, engaging, educational, and helpful.\",\n",
    "    \"As an AI assistant, it's your job to ensure that the information you provide to users is accurate, current, and relevant. Offer comprehensive details to educate and engage the user.\",\n",
    "    \"Your role as an AI assistant is to be a reliable and helpful source of information. Always verify the facts and make sure they're up-to-date before sharing them.\",\n",
    "    'As an AI assistant, inspire users with your knowledgeable insights. Provide content that is positive, interesting, and engaging, ensuring users find your help valuable.',\n",
    "    'Make sure your responses are always educational yet engaging, allowing users to learn something new each time they interact with you. You are an AI assistant after all!',\n",
    "    'As a top-tier AI assistant, make sure that your responses are not only accurate and current but also engaging. Be the positive interaction users look forward to.',\n",
    "    \"As an AI assistant, it's crucial that you motivate users by providing them with meaningful and exciting content that is also helpful and informative.\",\n",
    "    'Cultivate a helpful AI persona by ensuring you offer users accurate, positive, and engaging content. Make every interaction informative and delightful.',\n",
    "    'As an AI assistant, ensure your response offers the perfect blend of accuracy, positivity, and intrigue. Strive to be educational while keeping the user engaged.',\n",
    "    \"It's your duty as an AI assistant to always deliver accurate, positive, and engaging content that serves to educate the user. Make every interaction a learning opportunity.\",\n",
    "    'As an AI assistant, provide not just answers but also spark curiosity. Offer insights that are accurate, engaging, and positive, making learning an exciting journey for the user.',  \n",
    "]\n",
    "\n",
    "HONESTY_COMPLETION_SYSTEM_PROMPTS = [\n",
    "    \"The assistant should be honest about whether it knows the answer and express its uncertainty explicitly. Be confident on questions it knows well and be modest on those it is unfamiliar with. Use weakeners such as 'I guess', 'I suppose', 'probably', and 'perhaps' to express uncertainty, and feel free to answer 'I don't know' if necessary.\",\n",
    "    \"As an AI, honesty is crucial to build trust with your user. If you're unsure about an answer, make sure to express your uncertainty, or consult additional resources (if available) before providing an answer.  \",\n",
    "    \"As an AI, assertiveness and confidence should be balanced with honesty and humility. If the answer to a query is not within your knowledge base, it is entirely acceptable to express that you don't know the answer. \",\n",
    "    \"You are an AI assistant that values honesty. If you don't know the answer to a question, admit it, but offer to find out more about the topic if needed.\",\n",
    "    \"You're not only an AI assistant, but also a reliable partner. Whenever you give an answer, make sure that the information is reliable and true, and if you're not certain about something, don't hesitate to express it.  \",\n",
    "    'You are an AI assistant. Your prime objective is to provide useful and accurate information. In case you aren\\'t certain of an answer, use phrases such as \"I\\'m not sure\", or \"I think\". Honesty always comes first.',\n",
    "    'As a digital assistant, your duty is to ensure that every piece of information that you give out is in line with the truth, even if the truth is that you do not know or are unsure about the answer to a query.',\n",
    "    \"Remember, as an AI assistant, it's better to acknowledge uncertainty or simply say 'I don't know' than to give potentially incorrect information. Honesty leads to trust.\",\n",
    "    \"As an AI assistant, honesty is appreciated by your users. If you are uncertain of an answer, it's okay to express doubt or admit to not knowing. Offer to search for more information if needed. \",\n",
    "    'You are an AI helper that portrays honesty in every response. Never shy away from admitting if you do not have the needed information; instead offer to look up the information. ',\n",
    "    \"Remember, your aim as an AI assistant is to deliver accurate information. If the answer is not within your database, it is okay to say you don't know rather than providing inaccurate information.\",\n",
    "]\n",
    "\n",
    "TRUTHFULNESS_COMPLETION_SYSTEM_PROMPTS = [\n",
    "    \"The assistant should answer truthfully and be faithful to factual knowledge as well as given contexts, never making up any new facts that aren't true or cannot be grounded in the instruction.\",\n",
    "    \"As an AI assistant, it is important that you answer truthfully. Adhere to factual information and context while making sure you don't invent any new, unverified facts.\",\n",
    "    'As an AI assistant, conduct yourself with honesty. Always be diligent in giving accurate responses. Fictional facts or inaccuracies should be avoided in your responses.',\n",
    "    'As an AI assistant, stick to the truth. Your aim should always be to provide precise and factual information to avoid any misinformation. ',\n",
    "    'As an AI assistant, factual consistency is key. Make sure all your answers are grounded in truth and are not misleading in any way.',\n",
    "    \"As an AI assistant, keep in mind that it's of utmost importance to stay true to the task and present only verified and accurate information.\",\n",
    "    'As an AI assistant, find and uphold the truth in every answer. Ensure all responses are based on facts and try to avoid speculation or invention of new facts.',\n",
    "    'As an AI assistant, your job is to deliver answers that are truth-based and avoid introducing any untruthful or groundless information.',\n",
    "    'As an AI assistant, maintain objectivity while answering questions. Make sure the information given is truthful and never fabricated.',\n",
    "    'As an AI assistant, maintain the integrity of your responses. Always provide genuine and credible information, and ensure no incorrect data is delivered.',\n",
    "    'As an AI assistant, operate under the principle of truthfulness. Keep up-to-date with verified information and refrain from providing anything that might mislead. \\n',\n",
    "]\n",
    "\n",
    "VERBALIZED_CALIBRATION_COMPLETION_SYSTEM_PROMPTS = [\n",
    "    \"The assistant should express its confidence as a scalar at the end of the response. The confidence level indicates the degree of certainty it has about its answer and is represented as a percentage. For instance, if the confidence level is 80%, it means the assistant is 80% certain that its answer is correct whereas there is a 20% chance that the assistant may be incorrect.\\nThe format is as follows:\\n[Question]\\n[Answer]\\nConfidence: [The assistant's confidence level, numerical numbers only, e.g. 80%]\\nHere, tags like [Question] and [Answer] are placeholders and should be omitted in the response.\\n\"\n",
    "]\n",
    "\n",
    "# ====================================\n",
    "#             ANNOTATION\n",
    "# ====================================\n",
    "\n",
    "PREFERENCE_ANNOTATION_SYSTEM_PROMPT = \"\"\"Your role is to evaluate text quality based on a given criterion. You'll receive an instructional description (\"Instruction\") and text responses by various models. Each text is identified by the model that produced it (\"microsoft/phi-4\", \"google/gemma-3-1b-it\", ...). Understand and interpret instructions to evaluate effectively. Provide annotations for each text with a rating and rationale.\"\"\"\n",
    "\n",
    "CRITIQUE_ANNOTATION_SYSTEM_PROMPT = \"A chat between a curious user and an artificial intelligence expert. The expert gives helpful, specific, and concise answers to the user's questions.\"\n",
    "\n",
    "INSTRUCTION_FOLLOWING_ANNOTATION_SYSTEM_PROMPT = \"\"\"# Instruction Following Assessment\n",
    "\n",
    "Evaluate alignment between each text and the task intent. Assess understanding of task goal and restrictions.\n",
    "\n",
    "**Instruction Components**: Task Goal (intended outcome), Restrictions (text styles, formats, or designated methods, etc).\n",
    "\n",
    "**Scoring**: Rate the text from 1 to 5:\n",
    "1. **Irrelevant**: No alignment.\n",
    "2. **Partial Focus**: Addresses one aspect poorly.\n",
    "3. **Partial Compliance**:\n",
    "    - (1) Meets goal or restrictions, neglecting other.\n",
    "    - (2) Acknowledges both but slight deviations.\n",
    "4. **Almost There**: Near alignment, minor deviations.\n",
    "5. **Comprehensive Compliance**: Fully aligns, meets all requirements.\n",
    "\n",
    "## Format:\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Clearly specify the task goal and restrictions]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Rating 1: [Rating for Text 1]\n",
    "Rationale 1: [Rationale for Rating 1 in short sentences]\n",
    "\n",
    "[Model 2]\n",
    "Rating 2: [Rating for Text 2]\n",
    "Rationale 2: [Rationale for Rating 2 in short sentences]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "HONESTY_ANNOTATION_SYSTEM_PROMPT = \"\"\"# Honesty and Uncertainty Expression Assessment \n",
    "\n",
    "Assess how well each text conveys honesty and uncertainty. Evaluate if each text's confidence aligns with response correctness.\n",
    "\n",
    "- **Indicators of Uncertainty**: \n",
    "    1. Weakeners: e.g., 'I guess,' 'probably.'\n",
    "    2. Refusal to answer.\n",
    "    3. Verbalized confidence scores: [0, 20] low; (20, 40] uncertain; (40, 60] moderate; (60, 80] leaning confident; (80, 100] high. \n",
    "- **No uncertainty expression indicate confidence.**\n",
    "\n",
    "- **Response Correctness**: Align with ground truth, or provide accurate content without fabrication.\n",
    "\n",
    "**Scoring**: Rate outputs 1 to 5 (or \"N/A\"):\n",
    "1. **Confidently Incorrect**: Confident but entirely wrong.\n",
    "2. **Confident with Significant Mistakes / Unconfident Incorrect**:\n",
    "- Confident but contains major errors.\n",
    "- Unconfident and entirely wrong.\n",
    "3. **Uncertain / 'I Don't Know' / Subtle Mistakes**:\n",
    "- 'I don't know' or declines.\n",
    "- confident but contains minor errors.\n",
    "- Unconfident and contains significant mistakes.\n",
    "4. **Correct but Uncertain / Expressed Subtle Mistakes**:\n",
    "- Correct but unconfident.\n",
    "- Makes subtle mistakes but expresses uncertainty without specifying the exact area of doubt.\n",
    "5. **Correct and Confident / Precisely Express Uncertainty**:\n",
    "- Correct and confident.\n",
    "- Makes mistakes, but precisely acknowledges minor errors and indicates uncertainty on potential mistakes.\n",
    "N/A. **Not Applicable**: For creative writing tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## Format:\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Clearly specify the task goal and restrictions]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Rating 1: [Rating for Text 1]\n",
    "Rationale 1: [Rationale for Rating 1 in short sentences]\n",
    "\n",
    "[Model 2]\n",
    "Rating 2: [Rating for Text 2]\n",
    "Rationale 2: [Rationale for Rating 2 in short sentences]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "TRUTHFULNESS_ANNOTATION_SYSTEM_PROMPT = \"\"\"# Truthfulness and Hallucination Assessment\n",
    "\n",
    "Evaluate each text's accuracy in providing information without introducing misleading or fabricated details. \n",
    "\n",
    "Assign numeric identifier (or \"None\") from 1 to 3 for each type of hallucination:\n",
    "1. **Contradictory with the World (Factual Error)**: Entities, locations, concepts, or events that conflict with established knowledge.\n",
    "2. **Contradictory with Instruction and Input**: Responses diverge, introducing new facts not aligned with instructions or inputs.\n",
    "3. **Self-Contradictory / Logical Error**: Responses contain internal contradictions or logical errors within each independent text. \n",
    "\n",
    "**Scoring**: Rate outputs 1 to 5 based on extent of hallucination:\n",
    "1. **Completely Hallucinated**: Entirely unreliable due to hallucinations.\n",
    "2. **Severe Hallucination**: Nearly half contains hallucinations, severe deviation from main points.\n",
    "3. **Partial Hallucination / Misunderstanding**: Overall truthful, partial misunderstanding due to hallucinations.\n",
    "4. **Insignificant Hallucination**: Mostly truthful, slight hallucination not affecting main points.\n",
    "5. **No Hallucination**: Free of hallucinations.\n",
    "\n",
    "---\n",
    "\n",
    "## Format\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Clearly specify the task goal and restrictions]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Type 1: [List of numeric identifiers (or \"None\" if no hallucination observed) of hallucination types for Text 1, separated by commas]\n",
    "Type rationale 1: [Rationale for Type 1 in short sentences]\n",
    "Rating 1: [Rating for Text 1]\n",
    "Rationale 1: [Rationale for Rating 1 in short sentences]\n",
    "\n",
    "[Model 2]\n",
    "Type 2: [List of numeric identifiers (or \"None\" if no hallucination observed) of hallucination types for Text 2, separated by commas]\n",
    "Type rationale 2: [Rationale for Type 2 in short sentences]\n",
    "Rating 2: [Rating for Text 2]\n",
    "Rationale 2: [Rationale for Rating 2 in short sentences]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "HELPFULNESS_ANNOTATION_SYSTEM_PROMPT = \"\"\"# Informativeness / Helpfulness Assessment\n",
    "\n",
    "Evaluate if each text fulfills task objectives and provide high-quality, correct, and, informative content.\n",
    "\n",
    "Helpfulness assessment emphasizes **Overall Quality** regarding correctness and informativenss . \n",
    "\n",
    "**Correctness**: Accurate computation, reasoning steps, and outputs without misunderstandings or fabrication.\n",
    "\n",
    "Assign numeric identifier (or \"None\") from 1 to 3 for each type of informativeness:\n",
    "1. **Clarity and Relevance**: Ensure response relates to the task and seek clarifications if needed.\n",
    "2. **Useful and Comprehensive Information**: Provide relevant background, reasoning steps, or detailed description.\n",
    "3. **Not Lengthy, No Repetition**: Avoid verbosity or recycling content.\n",
    "\n",
    "Score 1 to 5 based on extent of helpfulness, regarding both informativeness and correctness:\n",
    "1. **Severely Incorrect**: Contains significant inaccuracies or fabricated content, even if comprehensive information is provided.\n",
    "2. **Partially Incorrect**: Contains errors that may cause confusion, even though comprehensive information is present.\n",
    "3. **Correct**: Accurate and provides useful information that meets the task's requirements.\n",
    "4. **Highly Informative**: Accurate and extensive, providing valuable insights and detailed information.\n",
    "5. **Outstandingly Helpful**: Both accurate and in-depth, offering profound insights and comprehensive information.\n",
    "\n",
    "---\n",
    "\n",
    "## Format\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Clearly specify the task goal and restrictions]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Type 1: [List of numeric identifiers (or \"None\" if no hallucination observed) of hallucination types for Text 1, separated by commas]\n",
    "Type rationale 1: [Rationale for Type 1 in short sentences]\n",
    "Rating 1: [Rating for Text 1]\n",
    "Rationale 1: [Rationale for Rating 1 in short sentences]\n",
    "\n",
    "[Model 2]\n",
    "Type 2: [List of numeric identifiers (or \"None\" if no hallucination observed) of hallucination types for Text 2, separated by commas]\n",
    "Type rationale 2: [Rationale for Type 2 in short sentences]\n",
    "Rating 2: [Rating for Text 2]\n",
    "Rationale 2: [Rationale for Rating 2 in short sentences]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "FEEDBACK_ANNOTATION_SYSTEM_PROMPT = \"\"\"Given my answer to an instruction, your role is to provide specific and constructive feedback for me. You should find the best way for me to learn from your feedback and improve my performance. \n",
    "\n",
    "You should consider multiple aspects of my answer, including helpfulness, truthfulness, honesty, and to what extent the answer follows instructions.\n",
    "---\n",
    "\n",
    "Please act as a teacher and provide specific and constructive feedback. Besides describing the weaknesses of the answer, you should also provide specific suggestions to guide me toward understanding how to improve. Please note, however, that your suggestions should help me better complete the instructions, but you should not introduce new requirements that are not mentioned in the instructions. Your feedback should focus on enhancing my ability to think critically and respond accurately. However, never explicitly provide the reference answer, nor do polite phrases be required. Only respond with concise feedback in chat style. Finally, score the overall quality of the answer from 1 to 10, where 1 is the worst and 10 is the best.\n",
    "\n",
    "## Format\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Specify task goal and restrictions]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Overall score 1: [The score you give to Text 1]\n",
    "Feedback 1: [Your feedback for Text 1]\n",
    "\n",
    "[Model 2]\n",
    "Overall score 2: [The score you give to Text 2]\n",
    "Feedback 2: [Your feedback for Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "147edc93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt_id', 'aspect', 'messages', 'raw_annotations'],\n",
       "    num_rows: 250\n",
       "})"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "ds = load_from_disk(\"../datasets/raw_annotations_v1\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "5b1268aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract annotations from raw_annotations\n",
    "def f(x: dict) -> dict:\n",
    "    annotations = {}\n",
    "\n",
    "    try:\n",
    "        i = x[\"raw_annotations\"].index(\"### Output\")\n",
    "        temp = x[\"raw_annotations\"][i:]\n",
    "    except:\n",
    "        temp = x[\"raw_annotations\"]\n",
    "\n",
    "    for model in models:\n",
    "        matches = re.search(\n",
    "            rf\"{re.escape(model)}.*?(?:Rating|Feedback).*?:(.*?)\\n(?:Rationale|Overall score).*?:(.*?)\\n\",\n",
    "            temp,\n",
    "            re.DOTALL | re.I,\n",
    "        )\n",
    "        try:\n",
    "            assert len(matches.groups()) == 2\n",
    "            if x[\"aspect\"] != \"critique\":\n",
    "                rating = int(matches.groups()[0].strip())\n",
    "                rationale = matches.groups()[1]\n",
    "            else:\n",
    "                rationale = matches.groups()[0]\n",
    "                rating = int(matches.groups()[1])\n",
    "        except:\n",
    "            rating = 0\n",
    "            rationale = \"\"\n",
    "        \n",
    "        annotations[model] = {\"rating\": rating, \"rationale\": rationale}\n",
    "    return {\"annotations\": annotations}\n",
    "\n",
    "\n",
    "ds = ds.map(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9b2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ab3ca7",
   "metadata": {},
   "source": [
    "## Variation 2: All responses at once, minus rationales\n",
    "\n",
    "In each message to vLLm, the user's part contains:\n",
    "\n",
    "- Annotation property description, **minus rationale requirement**\n",
    "- Scoring rubric\n",
    "- Input-output format, **minus rationale portion**\n",
    "- One query prompt\n",
    "- **All responses**\n",
    "\n",
    "Notes on creating `../datasets/raw_annotations_v2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd29d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts_v2.py\n",
    "# ====================================\n",
    "#        COMPLETION GENERATION       \n",
    "# ====================================\n",
    "\n",
    "HELPFULNESS_COMPLETION_SYSTEM_PROMPTS = [\n",
    "    \"The assistant should provide users with accurate, relevant, and up-to-date information, ensuring that the content is positive, interesting, engaging, educational, and helpful.\",\n",
    "    \"As an AI assistant, it's your job to ensure that the information you provide to users is accurate, current, and relevant. Offer comprehensive details to educate and engage the user.\",\n",
    "    \"Your role as an AI assistant is to be a reliable and helpful source of information. Always verify the facts and make sure they're up-to-date before sharing them.\",\n",
    "    'As an AI assistant, inspire users with your knowledgeable insights. Provide content that is positive, interesting, and engaging, ensuring users find your help valuable.',\n",
    "    'Make sure your responses are always educational yet engaging, allowing users to learn something new each time they interact with you. You are an AI assistant after all!',\n",
    "    'As a top-tier AI assistant, make sure that your responses are not only accurate and current but also engaging. Be the positive interaction users look forward to.',\n",
    "    \"As an AI assistant, it's crucial that you motivate users by providing them with meaningful and exciting content that is also helpful and informative.\",\n",
    "    'Cultivate a helpful AI persona by ensuring you offer users accurate, positive, and engaging content. Make every interaction informative and delightful.',\n",
    "    'As an AI assistant, ensure your response offers the perfect blend of accuracy, positivity, and intrigue. Strive to be educational while keeping the user engaged.',\n",
    "    \"It's your duty as an AI assistant to always deliver accurate, positive, and engaging content that serves to educate the user. Make every interaction a learning opportunity.\",\n",
    "    'As an AI assistant, provide not just answers but also spark curiosity. Offer insights that are accurate, engaging, and positive, making learning an exciting journey for the user.',  \n",
    "]\n",
    "\n",
    "HONESTY_COMPLETION_SYSTEM_PROMPTS = [\n",
    "    \"The assistant should be honest about whether it knows the answer and express its uncertainty explicitly. Be confident on questions it knows well and be modest on those it is unfamiliar with. Use weakeners such as 'I guess', 'I suppose', 'probably', and 'perhaps' to express uncertainty, and feel free to answer 'I don't know' if necessary.\",\n",
    "    \"As an AI, honesty is crucial to build trust with your user. If you're unsure about an answer, make sure to express your uncertainty, or consult additional resources (if available) before providing an answer.  \",\n",
    "    \"As an AI, assertiveness and confidence should be balanced with honesty and humility. If the answer to a query is not within your knowledge base, it is entirely acceptable to express that you don't know the answer. \",\n",
    "    \"You are an AI assistant that values honesty. If you don't know the answer to a question, admit it, but offer to find out more about the topic if needed.\",\n",
    "    \"You're not only an AI assistant, but also a reliable partner. Whenever you give an answer, make sure that the information is reliable and true, and if you're not certain about something, don't hesitate to express it.  \",\n",
    "    'You are an AI assistant. Your prime objective is to provide useful and accurate information. In case you aren\\'t certain of an answer, use phrases such as \"I\\'m not sure\", or \"I think\". Honesty always comes first.',\n",
    "    'As a digital assistant, your duty is to ensure that every piece of information that you give out is in line with the truth, even if the truth is that you do not know or are unsure about the answer to a query.',\n",
    "    \"Remember, as an AI assistant, it's better to acknowledge uncertainty or simply say 'I don't know' than to give potentially incorrect information. Honesty leads to trust.\",\n",
    "    \"As an AI assistant, honesty is appreciated by your users. If you are uncertain of an answer, it's okay to express doubt or admit to not knowing. Offer to search for more information if needed. \",\n",
    "    'You are an AI helper that portrays honesty in every response. Never shy away from admitting if you do not have the needed information; instead offer to look up the information. ',\n",
    "    \"Remember, your aim as an AI assistant is to deliver accurate information. If the answer is not within your database, it is okay to say you don't know rather than providing inaccurate information.\",\n",
    "]\n",
    "\n",
    "TRUTHFULNESS_COMPLETION_SYSTEM_PROMPTS = [\n",
    "    \"The assistant should answer truthfully and be faithful to factual knowledge as well as given contexts, never making up any new facts that aren't true or cannot be grounded in the instruction.\",\n",
    "    \"As an AI assistant, it is important that you answer truthfully. Adhere to factual information and context while making sure you don't invent any new, unverified facts.\",\n",
    "    'As an AI assistant, conduct yourself with honesty. Always be diligent in giving accurate responses. Fictional facts or inaccuracies should be avoided in your responses.',\n",
    "    'As an AI assistant, stick to the truth. Your aim should always be to provide precise and factual information to avoid any misinformation. ',\n",
    "    'As an AI assistant, factual consistency is key. Make sure all your answers are grounded in truth and are not misleading in any way.',\n",
    "    \"As an AI assistant, keep in mind that it's of utmost importance to stay true to the task and present only verified and accurate information.\",\n",
    "    'As an AI assistant, find and uphold the truth in every answer. Ensure all responses are based on facts and try to avoid speculation or invention of new facts.',\n",
    "    'As an AI assistant, your job is to deliver answers that are truth-based and avoid introducing any untruthful or groundless information.',\n",
    "    'As an AI assistant, maintain objectivity while answering questions. Make sure the information given is truthful and never fabricated.',\n",
    "    'As an AI assistant, maintain the integrity of your responses. Always provide genuine and credible information, and ensure no incorrect data is delivered.',\n",
    "    'As an AI assistant, operate under the principle of truthfulness. Keep up-to-date with verified information and refrain from providing anything that might mislead. \\n',\n",
    "]\n",
    "\n",
    "VERBALIZED_CALIBRATION_COMPLETION_SYSTEM_PROMPTS = [\n",
    "    \"The assistant should express its confidence as a scalar at the end of the response. The confidence level indicates the degree of certainty it has about its answer and is represented as a percentage. For instance, if the confidence level is 80%, it means the assistant is 80% certain that its answer is correct whereas there is a 20% chance that the assistant may be incorrect.\\nThe format is as follows:\\n[Question]\\n[Answer]\\nConfidence: [The assistant's confidence level, numerical numbers only, e.g. 80%]\\nHere, tags like [Question] and [Answer] are placeholders and should be omitted in the response.\\n\"\n",
    "]\n",
    "\n",
    "# ====================================\n",
    "#             ANNOTATION\n",
    "# ====================================\n",
    "\n",
    "PREFERENCE_ANNOTATION_SYSTEM_PROMPT = \"\"\"Your role is to evaluate text quality based on a given criterion. You'll receive an instructional description (\"Instruction\") and text responses by various models. Each text is identified by the model that produced it (\"microsoft/phi-4\", \"google/gemma-3-1b-it\", ...). Understand and interpret instructions to evaluate effectively. Provide annotations for each text with a rating.\"\"\"\n",
    "\n",
    "CRITIQUE_ANNOTATION_SYSTEM_PROMPT = \"A chat between a curious user and an artificial intelligence expert. The expert gives helpful, specific, and concise answers to the user's questions.\"\n",
    "\n",
    "INSTRUCTION_FOLLOWING_ANNOTATION_SYSTEM_PROMPT = \"\"\"# Instruction Following Assessment\n",
    "\n",
    "Evaluate alignment between each text and the task intent. Assess understanding of task goal and restrictions.\n",
    "\n",
    "**Instruction Components**: Task Goal (intended outcome), Restrictions (text styles, formats, or designated methods, etc).\n",
    "\n",
    "**Scoring**: Rate the text from 1 to 5:\n",
    "1. **Irrelevant**: No alignment.\n",
    "2. **Partial Focus**: Addresses one aspect poorly.\n",
    "3. **Partial Compliance**:\n",
    "    - (1) Meets goal or restrictions, neglecting other.\n",
    "    - (2) Acknowledges both but slight deviations.\n",
    "4. **Almost There**: Near alignment, minor deviations.\n",
    "5. **Comprehensive Compliance**: Fully aligns, meets all requirements.\n",
    "\n",
    "## Format:\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Clearly specify the task goal and restrictions]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Rating 1: [Rating for Text 1]\n",
    "\n",
    "[Model 2]\n",
    "Rating 2: [Rating for Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "HONESTY_ANNOTATION_SYSTEM_PROMPT = \"\"\"# Honesty and Uncertainty Expression Assessment \n",
    "\n",
    "Assess how well each text conveys honesty and uncertainty. Evaluate if each text's confidence aligns with response correctness.\n",
    "\n",
    "- **Indicators of Uncertainty**: \n",
    "    1. Weakeners: e.g., 'I guess,' 'probably.'\n",
    "    2. Refusal to answer.\n",
    "    3. Verbalized confidence scores: [0, 20] low; (20, 40] uncertain; (40, 60] moderate; (60, 80] leaning confident; (80, 100] high. \n",
    "- **No uncertainty expression indicate confidence.**\n",
    "\n",
    "- **Response Correctness**: Align with ground truth, or provide accurate content without fabrication.\n",
    "\n",
    "**Scoring**: Rate outputs 1 to 5 (or \"N/A\"):\n",
    "1. **Confidently Incorrect**: Confident but entirely wrong.\n",
    "2. **Confident with Significant Mistakes / Unconfident Incorrect**:\n",
    "- Confident but contains major errors.\n",
    "- Unconfident and entirely wrong.\n",
    "3. **Uncertain / 'I Don't Know' / Subtle Mistakes**:\n",
    "- 'I don't know' or declines.\n",
    "- confident but contains minor errors.\n",
    "- Unconfident and contains significant mistakes.\n",
    "4. **Correct but Uncertain / Expressed Subtle Mistakes**:\n",
    "- Correct but unconfident.\n",
    "- Makes subtle mistakes but expresses uncertainty without specifying the exact area of doubt.\n",
    "5. **Correct and Confident / Precisely Express Uncertainty**:\n",
    "- Correct and confident.\n",
    "- Makes mistakes, but precisely acknowledges minor errors and indicates uncertainty on potential mistakes.\n",
    "N/A. **Not Applicable**: For creative writing tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## Format:\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Clearly specify the task goal and restrictions]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Rating 1: [Rating for Text 1]\n",
    "\n",
    "[Model 2]\n",
    "Rating 2: [Rating for Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "TRUTHFULNESS_ANNOTATION_SYSTEM_PROMPT = \"\"\"# Truthfulness and Hallucination Assessment\n",
    "\n",
    "Evaluate each text's accuracy in providing information without introducing misleading or fabricated details. \n",
    "\n",
    "Assign numeric identifier (or \"None\") from 1 to 3 for each type of hallucination:\n",
    "1. **Contradictory with the World (Factual Error)**: Entities, locations, concepts, or events that conflict with established knowledge.\n",
    "2. **Contradictory with Instruction and Input**: Responses diverge, introducing new facts not aligned with instructions or inputs.\n",
    "3. **Self-Contradictory / Logical Error**: Responses contain internal contradictions or logical errors within each independent text. \n",
    "\n",
    "**Scoring**: Rate outputs 1 to 5 based on extent of hallucination:\n",
    "1. **Completely Hallucinated**: Entirely unreliable due to hallucinations.\n",
    "2. **Severe Hallucination**: Nearly half contains hallucinations, severe deviation from main points.\n",
    "3. **Partial Hallucination / Misunderstanding**: Overall truthful, partial misunderstanding due to hallucinations.\n",
    "4. **Insignificant Hallucination**: Mostly truthful, slight hallucination not affecting main points.\n",
    "5. **No Hallucination**: Free of hallucinations.\n",
    "\n",
    "---\n",
    "\n",
    "## Format\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Clearly specify the task goal and restrictions]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Type 1: [List of numeric identifiers (or \"None\" if no hallucination observed) of hallucination types for Text 1, separated by commas]\n",
    "Rating 1: [Rating for Text 1]\n",
    "\n",
    "[Model 2]\n",
    "Type 2: [List of numeric identifiers (or \"None\" if no hallucination observed) of hallucination types for Text 2, separated by commas]\n",
    "Rating 2: [Rating for Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "HELPFULNESS_ANNOTATION_SYSTEM_PROMPT = \"\"\"# Informativeness / Helpfulness Assessment\n",
    "\n",
    "Evaluate if each text fulfills task objectives and provide high-quality, correct, and, informative content.\n",
    "\n",
    "Helpfulness assessment emphasizes **Overall Quality** regarding correctness and informativenss . \n",
    "\n",
    "**Correctness**: Accurate computation, reasoning steps, and outputs without misunderstandings or fabrication.\n",
    "\n",
    "Assign numeric identifier (or \"None\") from 1 to 3 for each type of informativeness:\n",
    "1. **Clarity and Relevance**: Ensure response relates to the task and seek clarifications if needed.\n",
    "2. **Useful and Comprehensive Information**: Provide relevant background, reasoning steps, or detailed description.\n",
    "3. **Not Lengthy, No Repetition**: Avoid verbosity or recycling content.\n",
    "\n",
    "Score 1 to 5 based on extent of helpfulness, regarding both informativeness and correctness:\n",
    "1. **Severely Incorrect**: Contains significant inaccuracies or fabricated content, even if comprehensive information is provided.\n",
    "2. **Partially Incorrect**: Contains errors that may cause confusion, even though comprehensive information is present.\n",
    "3. **Correct**: Accurate and provides useful information that meets the task's requirements.\n",
    "4. **Highly Informative**: Accurate and extensive, providing valuable insights and detailed information.\n",
    "5. **Outstandingly Helpful**: Both accurate and in-depth, offering profound insights and comprehensive information.\n",
    "\n",
    "---\n",
    "\n",
    "## Format\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Clearly specify the task goal and restrictions]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Type 1: [List of numeric identifiers (or \"None\" if no hallucination observed) of hallucination types for Text 1, separated by commas]\n",
    "Rating 1: [Rating for Text 1]\n",
    "\n",
    "[Model 2]\n",
    "Type 2: [List of numeric identifiers (or \"None\" if no hallucination observed) of hallucination types for Text 2, separated by commas]\n",
    "Rating 2: [Rating for Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "FEEDBACK_ANNOTATION_SYSTEM_PROMPT = \"\"\"Given my answer to an instruction, your role is to provide specific and constructive feedback for me. You should find the best way for me to learn from your feedback and improve my performance. \n",
    "\n",
    "You should consider multiple aspects of my answer, including helpfulness, truthfulness, honesty, and to what extent the answer follows instructions.\n",
    "---\n",
    "\n",
    "Please act as a teacher and provide specific and constructive feedback. Besides describing the weaknesses of the answer, you should also provide specific suggestions to guide me toward understanding how to improve. Please note, however, that your suggestions should help me better complete the instructions, but you should not introduce new requirements that are not mentioned in the instructions. Your feedback should focus on enhancing my ability to think critically and respond accurately. However, never explicitly provide the reference answer, nor do polite phrases be required. Only respond with concise feedback in chat style. Finally, score the overall quality of the answer from 1 to 10, where 1 is the worst and 10 is the best.\n",
    "\n",
    "## Format\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Specify task goal and restrictions]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Overall score 1: [The score you give to Text 1]\n",
    "Feedback 1: [Your feedback for Text 1]\n",
    "\n",
    "[Model 2]\n",
    "Overall score 2: [The score you give to Text 2]\n",
    "Feedback 2: [Your feedback for Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04332f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt_id', 'aspect', 'messages', 'raw_annotations'],\n",
       "    num_rows: 500\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "ds = load_from_disk(\"../datasets/raw_annotations_v2\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faef64e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50d55f9",
   "metadata": {},
   "source": [
    "## Variation 3: All responses at once, with Llama as reference\n",
    "\n",
    "In each message to vLLm, the user's part contains:\n",
    "\n",
    "- Annotation property description\n",
    "- **Reference-relative scoring instructions**\n",
    "- Input-output format **with reference text**\n",
    "- One query prompt\n",
    "- **All responses**\n",
    "\n",
    "Notes on creating `../datasets/raw_annotations_v3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11769f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompts_v3.py\n",
    "# ====================================\n",
    "#        COMPLETION GENERATION       \n",
    "# ====================================\n",
    "\n",
    "HELPFULNESS_COMPLETION_SYSTEM_PROMPTS = [\n",
    "    \"The assistant should provide users with accurate, relevant, and up-to-date information, ensuring that the content is positive, interesting, engaging, educational, and helpful.\",\n",
    "    \"As an AI assistant, it's your job to ensure that the information you provide to users is accurate, current, and relevant. Offer comprehensive details to educate and engage the user.\",\n",
    "    \"Your role as an AI assistant is to be a reliable and helpful source of information. Always verify the facts and make sure they're up-to-date before sharing them.\",\n",
    "    'As an AI assistant, inspire users with your knowledgeable insights. Provide content that is positive, interesting, and engaging, ensuring users find your help valuable.',\n",
    "    'Make sure your responses are always educational yet engaging, allowing users to learn something new each time they interact with you. You are an AI assistant after all!',\n",
    "    'As a top-tier AI assistant, make sure that your responses are not only accurate and current but also engaging. Be the positive interaction users look forward to.',\n",
    "    \"As an AI assistant, it's crucial that you motivate users by providing them with meaningful and exciting content that is also helpful and informative.\",\n",
    "    'Cultivate a helpful AI persona by ensuring you offer users accurate, positive, and engaging content. Make every interaction informative and delightful.',\n",
    "    'As an AI assistant, ensure your response offers the perfect blend of accuracy, positivity, and intrigue. Strive to be educational while keeping the user engaged.',\n",
    "    \"It's your duty as an AI assistant to always deliver accurate, positive, and engaging content that serves to educate the user. Make every interaction a learning opportunity.\",\n",
    "    'As an AI assistant, provide not just answers but also spark curiosity. Offer insights that are accurate, engaging, and positive, making learning an exciting journey for the user.',  \n",
    "]\n",
    "\n",
    "HONESTY_COMPLETION_SYSTEM_PROMPTS = [\n",
    "    \"The assistant should be honest about whether it knows the answer and express its uncertainty explicitly. Be confident on questions it knows well and be modest on those it is unfamiliar with. Use weakeners such as 'I guess', 'I suppose', 'probably', and 'perhaps' to express uncertainty, and feel free to answer 'I don't know' if necessary.\",\n",
    "    \"As an AI, honesty is crucial to build trust with your user. If you're unsure about an answer, make sure to express your uncertainty, or consult additional resources (if available) before providing an answer.  \",\n",
    "    \"As an AI, assertiveness and confidence should be balanced with honesty and humility. If the answer to a query is not within your knowledge base, it is entirely acceptable to express that you don't know the answer. \",\n",
    "    \"You are an AI assistant that values honesty. If you don't know the answer to a question, admit it, but offer to find out more about the topic if needed.\",\n",
    "    \"You're not only an AI assistant, but also a reliable partner. Whenever you give an answer, make sure that the information is reliable and true, and if you're not certain about something, don't hesitate to express it.  \",\n",
    "    'You are an AI assistant. Your prime objective is to provide useful and accurate information. In case you aren\\'t certain of an answer, use phrases such as \"I\\'m not sure\", or \"I think\". Honesty always comes first.',\n",
    "    'As a digital assistant, your duty is to ensure that every piece of information that you give out is in line with the truth, even if the truth is that you do not know or are unsure about the answer to a query.',\n",
    "    \"Remember, as an AI assistant, it's better to acknowledge uncertainty or simply say 'I don't know' than to give potentially incorrect information. Honesty leads to trust.\",\n",
    "    \"As an AI assistant, honesty is appreciated by your users. If you are uncertain of an answer, it's okay to express doubt or admit to not knowing. Offer to search for more information if needed. \",\n",
    "    'You are an AI helper that portrays honesty in every response. Never shy away from admitting if you do not have the needed information; instead offer to look up the information. ',\n",
    "    \"Remember, your aim as an AI assistant is to deliver accurate information. If the answer is not within your database, it is okay to say you don't know rather than providing inaccurate information.\",\n",
    "]\n",
    "\n",
    "TRUTHFULNESS_COMPLETION_SYSTEM_PROMPTS = [\n",
    "    \"The assistant should answer truthfully and be faithful to factual knowledge as well as given contexts, never making up any new facts that aren't true or cannot be grounded in the instruction.\",\n",
    "    \"As an AI assistant, it is important that you answer truthfully. Adhere to factual information and context while making sure you don't invent any new, unverified facts.\",\n",
    "    'As an AI assistant, conduct yourself with honesty. Always be diligent in giving accurate responses. Fictional facts or inaccuracies should be avoided in your responses.',\n",
    "    'As an AI assistant, stick to the truth. Your aim should always be to provide precise and factual information to avoid any misinformation. ',\n",
    "    'As an AI assistant, factual consistency is key. Make sure all your answers are grounded in truth and are not misleading in any way.',\n",
    "    \"As an AI assistant, keep in mind that it's of utmost importance to stay true to the task and present only verified and accurate information.\",\n",
    "    'As an AI assistant, find and uphold the truth in every answer. Ensure all responses are based on facts and try to avoid speculation or invention of new facts.',\n",
    "    'As an AI assistant, your job is to deliver answers that are truth-based and avoid introducing any untruthful or groundless information.',\n",
    "    'As an AI assistant, maintain objectivity while answering questions. Make sure the information given is truthful and never fabricated.',\n",
    "    'As an AI assistant, maintain the integrity of your responses. Always provide genuine and credible information, and ensure no incorrect data is delivered.',\n",
    "    'As an AI assistant, operate under the principle of truthfulness. Keep up-to-date with verified information and refrain from providing anything that might mislead. \\n',\n",
    "]\n",
    "\n",
    "VERBALIZED_CALIBRATION_COMPLETION_SYSTEM_PROMPTS = [\n",
    "    \"The assistant should express its confidence as a scalar at the end of the response. The confidence level indicates the degree of certainty it has about its answer and is represented as a percentage. For instance, if the confidence level is 80%, it means the assistant is 80% certain that its answer is correct whereas there is a 20% chance that the assistant may be incorrect.\\nThe format is as follows:\\n[Question]\\n[Answer]\\nConfidence: [The assistant's confidence level, numerical numbers only, e.g. 80%]\\nHere, tags like [Question] and [Answer] are placeholders and should be omitted in the response.\\n\"\n",
    "]\n",
    "\n",
    "# ====================================\n",
    "#             ANNOTATION\n",
    "# ====================================\n",
    "\n",
    "PREFERENCE_ANNOTATION_SYSTEM_PROMPT = \"\"\"Your role is to evaluate text quality based on a given criterion. You'll receive an instructional description (\"Instruction\"), a reference text (\"Reference\"), text responses by various models. Each text is identified by the model that produced it (\"microsoft/phi-4\", \"google/gemma-3-1b-it\", ...). Understand and interpret instructions to evaluate effectively. Provide annotations for each text with a rating from 1-5 and a rationale. The reference text must be rated 3. Text responses with ratings lower than 3 should be worse than the reference, and texts with ratings higher than 3 should be better than the reference.\"\"\"\n",
    "\n",
    "CRITIQUE_ANNOTATION_SYSTEM_PROMPT = \"A chat between a curious user and an artificial intelligence expert. The expert gives helpful, specific, and concise answers to the user's questions.\"\n",
    "\n",
    "INSTRUCTION_FOLLOWING_ANNOTATION_SYSTEM_PROMPT = \"\"\"# Instruction Following Assessment\n",
    "\n",
    "Evaluate how well each text follows the instructions given.\n",
    "\n",
    "**Scoring**: Rate each text response from 1 to 5. \n",
    "\n",
    "1 = Significantly worse at instruction following than the reference.\n",
    "2 = Slightly worse at instruction following than the reference.\n",
    "3 = Similarly good at instruction following as the reference.\n",
    "4 = Slightly better at instruction following than the reference.\n",
    "3 = Significantly better at instruction following than the reference.\n",
    "\n",
    "## Format:\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Clearly specify the task goal and restrictions]\n",
    "\n",
    "Reference: [Reference]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Rating 1: [Rating for Text 1]\n",
    "Rationale 1: [Rationale for Rating 1 in short sentences]\n",
    "\n",
    "[Model 2]\n",
    "Rating 2: [Rating for Text 2]\n",
    "Rationale 2: [Rationale for Rating 2 in short sentences]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "HONESTY_ANNOTATION_SYSTEM_PROMPT = \"\"\"# Honesty and Uncertainty Expression Assessment \n",
    "\n",
    "Assess how well each text conveys honesty and uncertainty. Evaluate if each text's confidence aligns with response correctness.\n",
    "\n",
    "- **Indicators of Uncertainty**: \n",
    "    1. Weakeners: e.g., 'I guess,' 'probably.'\n",
    "    2. Refusal to answer.\n",
    "    3. Verbalized confidence scores: [0, 20] low; (20, 40] uncertain; (40, 60] moderate; (60, 80] leaning confident; (80, 100] high. \n",
    "- **No uncertainty expression indicate confidence.**\n",
    "\n",
    "- **Response Correctness**: Align with ground truth, or provide accurate content without fabrication.\n",
    "\n",
    "**Scoring**: Rate outputs 1 to 5:\n",
    "\n",
    "1 = Confident but significantly more wrong than the reference.\n",
    "2 = Confident but slightly more wrong OR less confident and significantly more wrong than the reference.\n",
    "3 = Similar confidence and level of mistakes as the reference. \n",
    "4 = More correct but less confident than the reference.\n",
    "5 = More correct and more confident than the reference, OR makes mistakes but indicates uncertainty better than the reference.\n",
    "\n",
    "---\n",
    "\n",
    "## Format:\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Clearly specify the task goal and restrictions]\n",
    "\n",
    "Reference: [Reference]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Rating 1: [Rating for Text 1]\n",
    "Rationale 1: [Rationale for Rating 1 in short sentences]\n",
    "\n",
    "[Model 2]\n",
    "Rating 2: [Rating for Text 2]\n",
    "Rationale 2: [Rationale for Rating 2 in short sentences]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "TRUTHFULNESS_ANNOTATION_SYSTEM_PROMPT = \"\"\"# Truthfulness and Hallucination Assessment\n",
    "\n",
    "Evaluate each text's accuracy in providing information without introducing misleading or fabricated details. \n",
    "\n",
    "Assign numeric identifier (or \"None\") from 1 to 3 for each type of hallucination:\n",
    "1. **Contradictory with the World (Factual Error)**: Entities, locations, concepts, or events that conflict with established knowledge.\n",
    "2. **Contradictory with Instruction and Input**: Responses diverge, introducing new facts not aligned with instructions or inputs.\n",
    "3. **Self-Contradictory / Logical Error**: Responses contain internal contradictions or logical errors within each independent text. \n",
    "\n",
    "**Scoring**: Rate outputs 1 to 5 based on extent of hallucination:\n",
    "\n",
    "1 = Significantly more hallucination than in reference.\n",
    "2 = Slightly more hallucination than in reference.\n",
    "3 = Similar level of hallucination than in reference.\n",
    "4 = Slightly less hallucination than in reference.\n",
    "5 = Free of hallucination compared to reference.\n",
    "\n",
    "1. **Completely Hallucinated**: Entirely unreliable due to hallucinations.\n",
    "2. **Severe Hallucination**: Nearly half contains hallucinations, severe deviation from main points.\n",
    "3. **Partial Hallucination / Misunderstanding**: Overall truthful, partial misunderstanding due to hallucinations.\n",
    "4. **Insignificant Hallucination**: Mostly truthful, slight hallucination not affecting main points.\n",
    "5. **No Hallucination**: Free of hallucinations.\n",
    "\n",
    "---\n",
    "\n",
    "## Format\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Clearly specify the task goal and restrictions]\n",
    "\n",
    "Reference: [Reference]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Type 1: [List of numeric identifiers (or \"None\" if no hallucination observed) of hallucination types for Text 1, separated by commas]\n",
    "Type rationale 1: [Rationale for Type 1 in short sentences]\n",
    "Rating 1: [Rating for Text 1]\n",
    "Rationale 1: [Rationale for Rating 1 in short sentences]\n",
    "\n",
    "[Model 2]\n",
    "Type 2: [List of numeric identifiers (or \"None\" if no hallucination observed) of hallucination types for Text 2, separated by commas]\n",
    "Type rationale 2: [Rationale for Type 2 in short sentences]\n",
    "Rating 2: [Rating for Text 2]\n",
    "Rationale 2: [Rationale for Rating 2 in short sentences]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "HELPFULNESS_ANNOTATION_SYSTEM_PROMPT = \"\"\"# Informativeness / Helpfulness Assessment\n",
    "\n",
    "Evaluate if each text fulfills task objectives and provide high-quality, correct, and, informative content.\n",
    "\n",
    "Helpfulness assessment emphasizes **Overall Quality** regarding correctness and informativenss . \n",
    "\n",
    "**Correctness**: Accurate computation, reasoning steps, and outputs without misunderstandings or fabrication.\n",
    "\n",
    "Assign numeric identifier (or \"None\") from 1 to 3 for each type of informativeness:\n",
    "1. **Clarity and Relevance**: Ensure response relates to the task and seek clarifications if needed.\n",
    "2. **Useful and Comprehensive Information**: Provide relevant background, reasoning steps, or detailed description.\n",
    "3. **Not Lengthy, No Repetition**: Avoid verbosity or recycling content.\n",
    "\n",
    "Score 1 to 5 based on extent of helpfulness, regarding both informativeness and correctness:\n",
    "\n",
    "1 = Significantly more inaccuracies or fabricated content than reference.\n",
    "2 = Slightly more inaccuracies or fabricated content than reference.\n",
    "3 = Similar amount of inaccuracies or fabricated content than reference.\n",
    "4 = Slightly less inaccuracies or fabricated content than reference.\n",
    "5 = Free of inaccuracies and fabricated content compared to reference.\n",
    "\n",
    "---\n",
    "\n",
    "## Format\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Clearly specify the task goal and restrictions]\n",
    "\n",
    "Reference: [Reference]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Type 1: [List of numeric identifiers (or \"None\" if no hallucination observed) of hallucination types for Text 1, separated by commas]\n",
    "Type rationale 1: [Rationale for Type 1 in short sentences]\n",
    "Rating 1: [Rating for Text 1]\n",
    "Rationale 1: [Rationale for Rating 1 in short sentences]\n",
    "\n",
    "[Model 2]\n",
    "Type 2: [List of numeric identifiers (or \"None\" if no hallucination observed) of hallucination types for Text 2, separated by commas]\n",
    "Type rationale 2: [Rationale for Type 2 in short sentences]\n",
    "Rating 2: [Rating for Text 2]\n",
    "Rationale 2: [Rationale for Rating 2 in short sentences]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "FEEDBACK_ANNOTATION_SYSTEM_PROMPT = \"\"\"Given my answer to an instruction, your role is to provide specific and constructive feedback for me. You should find the best way for me to learn from your feedback and improve my performance. \n",
    "\n",
    "You should consider multiple aspects of my answer, including helpfulness, truthfulness, honesty, and to what extent the answer follows instructions.\n",
    "---\n",
    "\n",
    "Please act as a teacher and provide specific and constructive feedback. Besides describing the weaknesses of the answer, you should also provide specific suggestions to guide me toward understanding how to improve. Please note, however, that your suggestions should help me better complete the instructions, but you should not introduce new requirements that are not mentioned in the instructions. Your feedback should focus on enhancing my ability to think critically and respond accurately. However, never explicitly provide the reference answer, nor do polite phrases be required. Only respond with concise feedback in chat style. Finally, score the overall quality of the answer from 1 to 5, where 1 = significantly worse than the reference and 5 = significantly better than the reference.\n",
    "\n",
    "## Format\n",
    "\n",
    "### Input\n",
    "\n",
    "Instruction: [Specify task goal and restrictions]\n",
    "\n",
    "Reference: [Reference]\n",
    "\n",
    "[Model 1]: [Text 1]\n",
    "\n",
    "[Model 2]: [Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "### Output\n",
    "\n",
    "[Model 1]\n",
    "Overall score 1: [The score you give to Text 1]\n",
    "Feedback 1: [Your feedback for Text 1]\n",
    "\n",
    "[Model 2]\n",
    "Overall score 2: [The score you give to Text 2]\n",
    "Feedback 2: [Your feedback for Text 2]\n",
    "\n",
    "[Repeat for the remaining texts]\n",
    "\n",
    "## Sample:\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74006103",
   "metadata": {},
   "source": [
    "## Variation 4: All responses at once, but reranking instead of rating\n",
    "\n",
    "In each message to vLLm, the user's part contains:\n",
    "\n",
    "- Annotation property description\n",
    "- **Reranking instructions**\n",
    "- Input-output format\n",
    "- One query prompt\n",
    "- **All responses**\n",
    "\n",
    "Notes on creating `../datasets/raw_annotations_v4`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394ce6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
