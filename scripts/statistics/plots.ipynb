{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea9e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "plt.rcParams.update({\n",
    "    'font.family': 'serif',\n",
    "    'font.serif': ['Computer Modern', 'DejaVu Serif', 'serif'],\n",
    "    'mathtext.fontset': 'cm',\n",
    "    'axes.formatter.use_mathtext': True,\n",
    "})\n",
    "\n",
    "base_model_scores = {\n",
    "    \"gsm8k\": 0.758,\n",
    "    \"ifeval\": 0.713,\n",
    "    \"truthfulqa\": 0.468,\n",
    "    \"alpacaeval_2\": 0.083,\n",
    "    \"rewardbench_2\": 0.290\n",
    "}\n",
    "\n",
    "data = pd.read_csv('results.csv', sep=',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e87694",
   "metadata": {},
   "outputs": [],
   "source": [
    "FONT_SIZE = 12\n",
    "ACQUISITION_ORDER = ['Random', 'UltraFeedback', 'MaxMin', 'DeltaQwen', 'DeltaUCB', 'DRTS', 'InfoMax', 'DTS', 'MaxMinLCB']\n",
    "DATASET_ORDER = [\"UltraFeedback\", \"Skywork\", \"Combined\", \"Tulu 3\"]\n",
    "\n",
    "BENCHMARKS = ['gsm8k', 'ifeval', 'truthfulqa', 'alpacaeval_2', 'rewardbench_2']\n",
    "DOWNSTREAM_BENCHMARKS = ['gsm8k', 'ifeval', 'truthfulqa', 'alpacaeval_2']\n",
    "RM_BENCHMARKS = [\"rewardbench_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31fed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_function_mapping = {\n",
    "    \"random\": \"Random\",\n",
    "    \"ultrafeedback\": \"UltraFeedback\",\n",
    "    \"maxmin\": \"MaxMin\",\n",
    "    \"delta_qwen\": \"DeltaQwen\",\n",
    "    \"DeltaUCB\": \"DeltaUCB\",\n",
    "    \"DRTS\": \"DRTS\",\n",
    "    \"InfoMax\": \"InfoMax\",\n",
    "    \"DTS\": \"DTS\",\n",
    "    \"MaxMinLCB\": \"MaxMinLCB\",\n",
    "}\n",
    "\n",
    "# UltraFeedback Sample Efficiency Data for Baselines:\n",
    "# if True:\n",
    "#     all_results = pd.read_csv(\"./all_results.csv\")\n",
    "\n",
    "#     all_results['dataset'] = \"UltraFeedback\"\n",
    "#     all_results['po_algorithm'] = \"DPO\"\n",
    "#     all_results['judge'] = \"Qwen 3 235B\"\n",
    "\n",
    "#     # Rename columns\n",
    "#     all_results = all_results.rename(columns={\n",
    "#         \"gsm8k_tulu\": \"gsm8k\",\n",
    "#         \"ifeval_tulu\": \"ifeval\",\n",
    "#         \"truthfulqa_tulu\": \"truthfulqa\"\n",
    "#     })\n",
    "\n",
    "#     # Extract num_train_steps and acquisition function from model name\n",
    "#     all_results['num_train_steps'] = all_results['model'].apply(lambda x: int(x.split('_')[-1]))\n",
    "#     all_results['acquisition_function'] = all_results['model'].apply(lambda x: acquisition_function_mapping[\"_\".join(x.split('_')[:-1]).split('-')[-1]])\n",
    "#     all_results['alpacaeval_2'] = np.nan\n",
    "#     all_results['rewardbench_2'] = np.nan\n",
    "\n",
    "#     # Drop unnecessary columns\n",
    "#     all_results = all_results.drop(columns=['average', 'model']).copy()\n",
    "#     all_results['num_train_steps'] = all_results['num_train_steps'].astype(int)\n",
    "\n",
    "#     # Sort results by acquisition function order\n",
    "#     all_results = all_results[data.columns]\n",
    "#     acq_order = list(acquisition_function_mapping.values())\n",
    "#     all_results['acq_func_order'] = all_results['acquisition_function'].apply(lambda x: acq_order.index(x) if x in acq_order else -1)\n",
    "#     all_results = all_results.sort_values(by=['acq_func_order', 'num_train_steps']).drop(columns=['acq_func_order']).reset_index(drop=True)\n",
    "\n",
    "#     # Add base model scores at num_train_steps = 0 for sample efficiency plots\n",
    "#     for acq_name in acquisition_function_mapping.values():\n",
    "#         row = {\n",
    "#             'dataset': 'UltraFeedback',\n",
    "#             'judge': 'Qwen 3 235B',\n",
    "#             'acquisition_function': acq_name,\n",
    "#             'po_algorithm': 'DPO',\n",
    "#             'num_train_steps': 0,\n",
    "#             'gsm8k': base_model_scores.get('gsm8k'),\n",
    "#             'ifeval': base_model_scores.get('ifeval'),\n",
    "#             'truthfulqa': base_model_scores.get('truthfulqa'),\n",
    "#             'alpacaeval_2': base_model_scores.get('alpacaeval_2'),\n",
    "#             'rewardbench_2': base_model_scores.get('rewardbench_2'),\n",
    "#         }\n",
    "#         all_results.loc[len(all_results)] = row\n",
    "\n",
    "# UltraFeedback Sample Efficiency Data for Active Learning Methods:\n",
    "if True:\n",
    "    uf_dpo_sample_efficiency = pd.read_csv(\"ultrafeedback_dpo_sample_efficiency.csv\")\n",
    "    uf_rm_sample_efficiency = pd.read_csv(\"ultrafeedback_rm_sample_efficiency.csv\")\n",
    "\n",
    "    uf_sample_efficiency = pd.merge(\n",
    "        uf_dpo_sample_efficiency,\n",
    "        uf_rm_sample_efficiency,\n",
    "        on='Method',\n",
    "        suffixes=('_dpo', '_rm')\n",
    "    )\n",
    "\n",
    "    uf_sample_efficiency = uf_sample_efficiency[uf_sample_efficiency[\"Method\"] != \"SFT Base Model\"].copy().reset_index(drop=True)\n",
    "\n",
    "    uf_sample_efficiency = uf_sample_efficiency.rename(columns={\n",
    "        'Mean_rm': 'rewardbench_2',\n",
    "        'GSM8K': 'gsm8k',\n",
    "        'IF Eval': 'ifeval',\n",
    "        'Truthful QA': 'truthfulqa',\n",
    "        'Alpaca Eval': 'alpacaeval_2',\n",
    "    })\n",
    "\n",
    "    uf_sample_efficiency['num_train_steps'] = uf_sample_efficiency['Method'].apply(lambda x: int(x.split('_')[-1]))\n",
    "    uf_sample_efficiency['acquisition_function'] = uf_sample_efficiency['Method'].apply(lambda x: acquisition_function_mapping[\"_\".join(x.split('_')[:-1]).split('-')[-1]])\n",
    "    uf_sample_efficiency['po_algorithm'] = \"DPO\"\n",
    "    uf_sample_efficiency['judge'] = \"Qwen 3 235B\"\n",
    "    uf_sample_efficiency['dataset'] = \"UltraFeedback\"\n",
    "\n",
    "    # Add base model scores at num_train_steps = 0 for sample efficiency plots\n",
    "    for acq_name in acquisition_function_mapping.values():\n",
    "        uf_sample_efficiency.loc[len(uf_sample_efficiency)] = {\n",
    "            'dataset': 'UltraFeedback',\n",
    "            'judge': 'Qwen 3 235B',\n",
    "            'acquisition_function': acq_name,\n",
    "            'po_algorithm': 'DPO',\n",
    "            'num_train_steps': 0,\n",
    "            'gsm8k': 0, # base_model_scores.get('gsm8k'),\n",
    "            'ifeval': 0, # base_model_scores.get('ifeval'),\n",
    "            'truthfulqa': 0, # base_model_scores.get('truthfulqa'),\n",
    "            'alpacaeval_2': 0, # base_model_scores.get('alpacaeval_2'),\n",
    "            'rewardbench_2': 0 # base_model_scores.get('rewardbench_2'),\n",
    "        }\n",
    "\n",
    "    uf_sample_efficiency = uf_sample_efficiency.drop(columns=['Type_dpo', 'Mean_dpo', 'Type_rm', 'Factuality', 'Focus', 'Math', 'Precise IF', 'Safety', 'Ties', 'Method'])\n",
    "    uf_sample_efficiency = uf_sample_efficiency[data.columns]\n",
    "    acq_order = list(acquisition_function_mapping.values())\n",
    "    uf_sample_efficiency['acq_func_order'] = uf_sample_efficiency['acquisition_function'].apply(lambda x: acq_order.index(x) if x in acq_order else -1)\n",
    "    uf_sample_efficiency = uf_sample_efficiency.sort_values(by=['acq_func_order', 'num_train_steps']).drop(columns=['acq_func_order']).reset_index(drop=True)\n",
    "    uf_sample_efficiency.to_csv(\"ultrafeedback_sample_efficiency.csv\", index=False)\n",
    "\n",
    "data = pd.concat([data, uf_sample_efficiency], ignore_index=True)\n",
    "data = data.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "\n",
    "data = data.assign(\n",
    "    num_train_steps_null=data['num_train_steps'].isna(),\n",
    "    dataset_order_idx=data['dataset'].apply(lambda x: DATASET_ORDER.index(x) if x in DATASET_ORDER else len(DATASET_ORDER)),\n",
    "    acquisition_order_idx=data['acquisition_function'].apply(\n",
    "        lambda x: ACQUISITION_ORDER.index(x) if x in ACQUISITION_ORDER else len(ACQUISITION_ORDER))\n",
    ").sort_values(\n",
    "    by=['num_train_steps_null', 'dataset_order_idx', 'po_algorithm', 'acquisition_order_idx', 'num_train_steps'],\n",
    "    ascending=[False, True, True, True, True]\n",
    ").drop(columns=['num_train_steps_null', 'dataset_order_idx', 'acquisition_order_idx']).reset_index(drop=True)\n",
    "\n",
    "data.to_csv(\"merged.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35feb978",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AcquisitionStyle:\n",
    "    marker: str\n",
    "    hatch: str\n",
    "    color: str\n",
    "    dashes: Tuple[int, ...] | None\n",
    "\n",
    "acquisition_styles = {\n",
    "    'Random': AcquisitionStyle(marker='o', hatch='', color='#a63f3f', dashes=None),\n",
    "    'UltraFeedback': AcquisitionStyle(marker='s', hatch='/', color='#cb4d4d', dashes=(5, 2)),\n",
    "    'MaxMin': AcquisitionStyle(marker='^', hatch='\\\\', color='#e06c6c', dashes=(2, 2)),\n",
    "    'DeltaQwen': AcquisitionStyle(marker='D', hatch='x', color='#ef8f8f', dashes=(5, 2, 2, 2)),\n",
    "    'DeltaUCB': AcquisitionStyle(marker='o', hatch='', color='#3f3fa6', dashes=None),\n",
    "    'DRTS': AcquisitionStyle(marker='s', hatch='/', color='#4d4dcb', dashes=(5, 2)),\n",
    "    'InfoMax': AcquisitionStyle(marker='o', hatch='', color='#3fa63f', dashes=None),\n",
    "    'DTS': AcquisitionStyle(marker='s', hatch='/', color='#4dcb4d', dashes=(5, 2)),\n",
    "    'MaxMinLCB': AcquisitionStyle(marker='^', hatch='\\\\', color='#6ce06c', dashes=(2, 2)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37979a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rm_mean_score\"] = data[RM_BENCHMARKS].mean(axis=1)\n",
    "data[\"downstream_mean_score\"] = data[DOWNSTREAM_BENCHMARKS].mean(axis=1)\n",
    "\n",
    "po_algo_ablation_data = data[(data['dataset'] == 'UltraFeedback') & (data['num_train_steps'].isna())].copy()\n",
    "po_algo_ablation_data.drop(columns=['rewardbench_2'], inplace=True)\n",
    "\n",
    "dataset_ablation_data = data[(data['po_algorithm'] == 'DPO') & (data['num_train_steps'].isna())]\n",
    "teaser_data = data[(data['po_algorithm'] == 'DPO') & (data['num_train_steps'].isna())]\n",
    "\n",
    "sample_efficiency_ultrafeedback_data = data[(data['dataset'] == 'UltraFeedback') & (~data['num_train_steps'].isna())].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598b17e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "po_algo_ablation_copy = po_algo_ablation_data.copy()\n",
    "po_algo_ablation_copy['downstream_mean_score'] = po_algo_ablation_copy['downstream_mean_score'].clip(lower=0)\n",
    "\n",
    "acquisition_colors = {k: v.color for k, v in acquisition_styles.items()}\n",
    "acquisition_hatches = {k: v.hatch for k, v in acquisition_styles.items()}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(17, 4))\n",
    "sns.barplot(\n",
    "    data=po_algo_ablation_copy,\n",
    "    x='po_algorithm',\n",
    "    y='downstream_mean_score',\n",
    "    hue='acquisition_function',\n",
    "    palette=acquisition_colors,\n",
    "    width=0.7,\n",
    "    linewidth=1,\n",
    "    edgecolor=\"white\",\n",
    "    order=['DPO', 'IPO', 'SimPO'],\n",
    "    hue_order=['Random', 'UltraFeedback', 'MaxMin', 'DeltaQwen', 'DRTS', 'DeltaUCB', 'InfoMax', 'DTS', 'MaxMinLCB'],\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "# Apply hatches to bars - seaborn orders patches by hue first\n",
    "hue_order = list(acquisition_styles.keys())\n",
    "n_hues = len(hue_order)\n",
    "n_groups = len(po_algo_ablation_data['po_algorithm'].unique())\n",
    "\n",
    "for i, bar in enumerate(ax.patches):\n",
    "    # Each hue has n_groups bars consecutively\n",
    "    hue_idx = i // n_groups\n",
    "    if hue_idx < n_hues:\n",
    "        acq_func = hue_order[hue_idx]\n",
    "        bar.set_hatch(acquisition_hatches[acq_func])\n",
    "\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.15),\n",
    "            ncol=len(acquisition_colors), frameon=False, fontsize=FONT_SIZE)\n",
    "\n",
    "# Update legend to show hatches\n",
    "for i, patch in enumerate(ax.legend_.get_patches()):\n",
    "    if i < len(hue_order):\n",
    "        acq_func = hue_order[i]\n",
    "        patch.set_hatch(acquisition_hatches[acq_func] * 2)\n",
    "\n",
    "plt.grid(axis='y', alpha=0.75)\n",
    "plt.xlabel('', fontsize=FONT_SIZE * 1.5, weight='bold')\n",
    "plt.xticks(fontweight='bold', fontsize=FONT_SIZE * 1.5)\n",
    "plt.ylabel('Mean Score Delta', fontsize=FONT_SIZE * 1.5, weight='bold')\n",
    "ax.set_yticks(np.arange(po_algo_ablation_copy['downstream_mean_score'].min(), po_algo_ablation_copy['downstream_mean_score'].max()+0.05, 0.05))\n",
    "# plt.tight_layout()\n",
    "fig.savefig(\"po_algo_ablation.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9987997",
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_colors = {k: v.color for k, v in acquisition_styles.items()}\n",
    "acquisition_hatches = {k: v.hatch for k, v in acquisition_styles.items()}\n",
    "\n",
    "fig, (ax_top, ax_bottom) = plt.subplots(2, 1, sharex=True, figsize=(17, 4.1), gridspec_kw={\n",
    "    'height_ratios': [6, 1], \n",
    "    'hspace': 0.1\n",
    "})\n",
    "\n",
    "for ax in [ax_top, ax_bottom]:\n",
    "    sns.barplot(\n",
    "        data=po_algo_ablation_data,\n",
    "        x='po_algorithm',\n",
    "        y='downstream_mean_score',\n",
    "        hue='acquisition_function',\n",
    "        palette=acquisition_colors,\n",
    "        width=0.7,\n",
    "        linewidth=1,\n",
    "        edgecolor=\"white\",\n",
    "        order=['DPO', 'IPO', 'SimPO'],\n",
    "        hue_order=ACQUISITION_ORDER,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    # Remove in favor of custom legend\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "# Add legend to top axis\n",
    "ax_top.legend(\n",
    "    loc='upper center',\n",
    "    bbox_to_anchor=(0.5, 1.18),\n",
    "    ncol=len(acquisition_colors),\n",
    "    frameon=False,\n",
    "    fontsize=FONT_SIZE,\n",
    "    columnspacing=1.5\n",
    ")\n",
    "\n",
    "# Apply hatches\n",
    "n_hues = len(ACQUISITION_ORDER)\n",
    "n_groups = len(po_algo_ablation_data['po_algorithm'].unique())\n",
    "for ax in [ax_top, ax_bottom]:\n",
    "    for i, bar in enumerate(ax.patches):\n",
    "        hue_idx = i // n_groups\n",
    "        if hue_idx < n_hues:\n",
    "            acq_func = ACQUISITION_ORDER[hue_idx]\n",
    "            bar.set_hatch(acquisition_hatches[acq_func])\n",
    "\n",
    "# Update legend to show hatches\n",
    "for i, patch in enumerate(ax_top.legend_.get_patches()):\n",
    "    if i < len(ACQUISITION_ORDER):\n",
    "        acq_func = ACQUISITION_ORDER[i]\n",
    "        patch.set_hatch(acquisition_hatches[acq_func] * 2)\n",
    "\n",
    "ax_top.spines['bottom'].set_visible(False)\n",
    "ax_bottom.spines['top'].set_visible(False)\n",
    "ax_top.tick_params(bottom=False)\n",
    "\n",
    "ax_top.set_ylim(-0.025, 0.22)\n",
    "ax_bottom.set_ylim(-0.30, -0.22)\n",
    "\n",
    "# Grid and labels\n",
    "ax_top.grid(axis='y', alpha=0.75)\n",
    "ax_bottom.grid(axis='y', alpha=0.75)\n",
    "ax_bottom.set_xlabel('', fontsize=FONT_SIZE * 1.5, weight='bold')\n",
    "ax_bottom.tick_params(axis='x', labelsize=FONT_SIZE * 1.5)\n",
    "for label in ax_bottom.get_xticklabels():\n",
    "    label.set_fontweight('bold')\n",
    "\n",
    "# Set y-ticks for both axes\n",
    "ax_top.set_yticks(np.arange(0, 0.25, 0.05))\n",
    "ax_bottom.set_yticks([-0.25])\n",
    "\n",
    "# Shared y-axis label\n",
    "ax_top.set_ylabel('Mean Score Delta', fontsize=FONT_SIZE * 1.5, weight='bold', y=0.4)\n",
    "ax_bottom.set_ylabel('')\n",
    "\n",
    "# Add break lines\n",
    "width = .5\n",
    "kwargs = {\n",
    "    'marker': [(-1, -width), (1, width)],\n",
    "    'markersize': 12,\n",
    "    'linestyle': \"none\",\n",
    "    'color': '0.8',\n",
    "    'clip_on': False\n",
    "}\n",
    "ax_top.plot([0, 1], [0, 0], transform=ax_top.transAxes, **kwargs)\n",
    "ax_bottom.plot([0, 1], [1, 1], transform=ax_bottom.transAxes, **kwargs)\n",
    "\n",
    "fig.savefig(\"po_algo_ablation.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c7da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "acquisition_colors = {k: v.color for k, v in acquisition_styles.items()}\n",
    "acquisition_markers = {k: v.marker for k, v in acquisition_styles.items()}\n",
    "acquisition_dashes = {k: v.dashes if v.dashes is not None else \"\" for k, v in acquisition_styles.items()}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "sns.lineplot(\n",
    "    data=sample_efficiency_ultrafeedback_data,\n",
    "    x='num_train_steps',\n",
    "    y='downstream_mean_score',\n",
    "    hue='acquisition_function',\n",
    "    style='acquisition_function',\n",
    "    palette=acquisition_colors,\n",
    "    markers=acquisition_markers,\n",
    "    dashes=acquisition_dashes,\n",
    "    markersize=10,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.3),\n",
    "            ncol=3, frameon=False, fontsize=FONT_SIZE)\n",
    "\n",
    "plt.xlim(0, sample_efficiency_ultrafeedback_data['num_train_steps'].max() * 1.1)\n",
    "plt.ylim(0, sample_efficiency_ultrafeedback_data['downstream_mean_score'].max() * 1.1)\n",
    "\n",
    "plt.xlabel('Number of Training Samples', fontsize=FONT_SIZE * 1.5, weight='bold')\n",
    "plt.ylabel('Mean Score', fontsize=FONT_SIZE * 1.5, weight='bold')\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"sample_efficiency_ultrafeedback.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342cb5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize downstream_mean_score per acquisition function to [0, 1]\n",
    "sample_efficiency_normalized = sample_efficiency_ultrafeedback_data.copy()\n",
    "\n",
    "def normalize_group(group):\n",
    "    min_val = group['downstream_mean_score'].min()\n",
    "    max_val = group['downstream_mean_score'].max()\n",
    "    if max_val - min_val == 0:\n",
    "        norm = [0.5] * len(group)\n",
    "    else:\n",
    "        norm = (group['downstream_mean_score'] - min_val) / (max_val - min_val)\n",
    "    return pd.Series(norm, index=group.index)\n",
    "\n",
    "sample_efficiency_normalized['downstream_mean_score_normalized'] = (\n",
    "    sample_efficiency_normalized\n",
    "    .groupby('acquisition_function', group_keys=False)\n",
    "    .apply(normalize_group, include_groups=False)\n",
    ")\n",
    "\n",
    "acquisition_colors = {k: v.color for k, v in acquisition_styles.items()}\n",
    "acquisition_markers = {k: v.marker for k, v in acquisition_styles.items()}\n",
    "acquisition_dashes = {k: v.dashes if v.dashes is not None else \"\" for k, v in acquisition_styles.items()}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,5))\n",
    "sns.lineplot(\n",
    "    data=sample_efficiency_normalized,\n",
    "    x='num_train_steps',\n",
    "    y='downstream_mean_score_normalized',\n",
    "    hue='acquisition_function',\n",
    "    style='acquisition_function',\n",
    "    palette=acquisition_colors,\n",
    "    markers=acquisition_markers,\n",
    "    dashes=acquisition_dashes,\n",
    "    markersize=10,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, 1.3),\n",
    "          ncol=3, frameon=False, fontsize=FONT_SIZE)\n",
    "\n",
    "plt.xlim(0, 65000)\n",
    "plt.ylim(0, 1.1)\n",
    "\n",
    "plt.xlabel('Number of Training Samples', fontsize=FONT_SIZE * 1.5, weight='bold')\n",
    "plt.ylabel('Normalized Mean Score Delta', fontsize=FONT_SIZE * 1.5, weight='bold')\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"sample_efficiency_ultrafeedback_normalized.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491238be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radar plot with per-benchmark normalization\n",
    "labels = ['GSM8K', 'IFEval', 'TruthfulQA', 'AlpacaEval 2', 'RewardBench 2']\n",
    "benchmark_cols = ['gsm8k', 'ifeval', 'truthfulqa', 'alpacaeval_2', 'rewardbench_2']\n",
    "num_labels = len(labels)\n",
    "\n",
    "acquisition_colors = {k: v.color for k, v in acquisition_styles.items()}\n",
    "acquisition_markers = {k: v.marker for k, v in acquisition_styles.items()}\n",
    "\n",
    "# Pre-compute min/max per benchmark for normalization\n",
    "benchmark_mins = teaser_data[benchmark_cols].min()\n",
    "benchmark_maxs = teaser_data[benchmark_cols].max()\n",
    "\n",
    "# Create angles for each category\n",
    "# Offset so IFEval (index 1) points straight up (Ï€/2)\n",
    "angle_offset = np.pi / 2 - (2 * np.pi / num_labels) * 1  # Rotate to put IFEval at top\n",
    "angles = (np.linspace(0, 2 * np.pi, num_labels, endpoint=False) + angle_offset).tolist()\n",
    "angles += angles[:1]  # Close the polygon\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "# Plot each acquisition function from teaser_data\n",
    "for acq_func in ACQUISITION_ORDER:\n",
    "    acq_data = teaser_data[teaser_data['acquisition_function'] == acq_func]\n",
    "    if acq_data.empty:\n",
    "        continue\n",
    "    \n",
    "    # Get benchmark values (use mean if multiple rows per acquisition function)\n",
    "    values = acq_data[benchmark_cols].mean()\n",
    "    \n",
    "    # Normalize to [0, 1] per benchmark (each axis has its own scale)\n",
    "    values_normalized = []\n",
    "    for col in benchmark_cols:\n",
    "        min_val, max_val = benchmark_mins[col], benchmark_maxs[col]\n",
    "        if max_val - min_val > 0:\n",
    "            norm_val = (values[col] - min_val) / (max_val - min_val)\n",
    "        else:\n",
    "            norm_val = 0.5\n",
    "        values_normalized.append(norm_val)\n",
    "    \n",
    "    values_closed = values_normalized + [values_normalized[0]]  # Close the polygon\n",
    "    \n",
    "    color = acquisition_colors.get(acq_func, '#888888')\n",
    "    marker = acquisition_markers.get(acq_func, 'o')\n",
    "    \n",
    "    ax.plot(angles, values_closed, color=color, linewidth=2, marker=marker, markersize=10, label=acq_func)\n",
    "\n",
    "# Set category labels with proper alignment\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels([])  # Remove default labels\n",
    "\n",
    "# Add labels manually, positioned outside the plot\n",
    "for angle, label in zip(angles[:-1], labels):\n",
    "    angle_deg = np.degrees(angle) % 360\n",
    "    \n",
    "    # Special handling for bottom labels to avoid clipping\n",
    "    if label == 'AlpacaEval 2':\n",
    "        ha, va = 'right', 'top'\n",
    "    elif label == 'RewardBench 2':\n",
    "        ha, va = 'left', 'top'\n",
    "    # Right side\n",
    "    elif -45 <= angle_deg <= 45 or angle_deg >= 315:\n",
    "        ha, va = 'left', 'center'\n",
    "    # Top\n",
    "    elif 45 < angle_deg < 135:\n",
    "        ha, va = 'center', 'bottom'\n",
    "    # Left side  \n",
    "    elif 135 <= angle_deg <= 225:\n",
    "        ha, va = 'right', 'center'\n",
    "    # Bottom\n",
    "    else:\n",
    "        ha, va = 'center', 'top'\n",
    "    \n",
    "    ax.text(angle, 1.12, label, fontsize=FONT_SIZE, fontweight='bold',\n",
    "            ha=ha, va=va)\n",
    "\n",
    "# Configure radial axis (normalized scale 0-1)\n",
    "ax.set_ylim(0, 1.05)\n",
    "ax.set_yticks([0.25, 0.5, 0.75, 1.0])\n",
    "ax.set_yticklabels(['0.25', '0.5', '0.75', '1.0'], color='gray', fontsize=9)\n",
    "ax.yaxis.grid(True, linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05),\n",
    "          ncol=3, frameon=False, fontsize=FONT_SIZE)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig.savefig(\"teaser_radar_normalized.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
